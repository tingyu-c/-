import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
from PIL import Image

# ç¢ºä¿é€™å…©å€‹æª”æ¡ˆåœ¨åŒä¸€ç›®éŒ„ä¸‹
from dataset import InvoiceSegDataset
from unet_model import UNet

import torchvision.transforms as T

# ----------------------------
# è¼”åŠ©å‡½å¼ï¼šå°‡æ­£è¦åŒ–çš„åœ–ç‰‡è½‰å› PIL åœ–ç‰‡
# ----------------------------
def visualize_epoch(img, true_mask, pred_mask, save_prefix):
    """
    è¼¸å‡ºè¨“ç·´å¯è¦–åŒ–ï¼š
    - img: è¼¸å…¥åœ–ç‰‡ (Tensor)
    - true_mask: çœŸå¯¦é®ç½© (Tensor, å€¼åŸŸ 0~3)
    - pred_mask: é æ¸¬é®ç½© (Tensor, å€¼åŸŸ 0~3)
    """
    os.makedirs("visualize", exist_ok=True)

    # ImageNet æ¨™æº–åŒ–åƒæ•¸ (ç”¨æ–¼åæ­£è¦åŒ–)
    MEAN = [0.485, 0.456, 0.406]
    STD = [0.229, 0.224, 0.225]

    # åæ­£è¦åŒ–
    inv_normalize = T.Normalize(
        mean=[-m/s for m, s in zip(MEAN, STD)],
        std=[1/s for s in STD]
    )
    img = inv_normalize(img.clone())
    
    # å°‡åœ–ç‰‡å¾ Tensor è½‰ç‚º numpy (H, W, C) ä¸¦è½‰æ›ç‚º 0-255 æ•´æ•¸
    img_np = (img.numpy().transpose(1, 2, 0) * 255).clip(0, 255).astype(np.uint8)
    Image.fromarray(img_np).save(f"visualize/{save_prefix}_img.png")

    # é®ç½©å¯è¦–åŒ–ï¼šå°‡ 0~3 çš„é¡åˆ¥ ID æ˜ å°„åˆ° 0~255 çš„ç°åº¦å€¼
    # é¡åˆ¥ 0=0, 1=85, 2=170, 3=255
    color_scale = 255 // 3 
    
    true_mask_vis = (true_mask.numpy() * color_scale).astype(np.uint8)
    Image.fromarray(true_mask_vis).save(
        f"visualize/{save_prefix}_true_mask.png"
    )

    pred_mask_vis = (pred_mask.numpy() * color_scale).astype(np.uint8)
    Image.fromarray(pred_mask_vis).save(
        f"visualize/{save_prefix}_pred_mask.png"
    )


# ----------------------------
# ä¸»ç¨‹å¼
# ----------------------------
def main():
    images_dir = "data/images"
    masks_dir = "masks"
    checkpoint_dir = "checkpoints"
    os.makedirs(checkpoint_dir, exist_ok=True)

    # ğŸš¨ ä¿®æ­£: é¡åˆ¥æ•¸å¿…é ˆèˆ‡ inference.py ä¸€è‡´ (0=èƒŒæ™¯, 1=è™Ÿç¢¼, 2=æ—¥æœŸ, 3=é‡‘é¡)
    N_CLASSES = 4 
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨è£ç½®: {device}")

    # æ•¸æ“šå¢å¼· (Data Augmentation)
    transform = T.Compose([
        T.Resize((256, 256)),
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet æ¨™æº–åŒ–
    ])
    
    # é®ç½©è™•ç†ï¼šåªéœ€è¦ Resizeï¼Œä¸éœ€è¦ ToTensor æˆ– Normalize
    mask_transform = T.Compose([
        T.Resize((256, 256), interpolation=T.InterpolationMode.NEAREST),
    ])

    dataset = InvoiceSegDataset(images_dir, masks_dir, transform, mask_transform)
    loader = DataLoader(dataset, batch_size=4, shuffle=True)
    
    if len(dataset) == 0:
        print("ğŸš¨ éŒ¯èª¤: è³‡æ–™é›†ç‚ºç©ºã€‚è«‹ç¢ºèª 'data/images' å’Œ 'masks' è³‡æ–™å¤¾ä¸­æœ‰å°æ‡‰çš„åœ–ç‰‡å’Œé®ç½©æª”æ¡ˆã€‚")
        return

    # ğŸš¨ ä¿®æ­£: é¡åˆ¥æ•¸æ”¹ç‚º N_CLASSES=4
    model = UNet(n_channels=3, n_classes=N_CLASSES).to(device)

    # ğŸš¨ ä¿®æ­£: æå¤±å‡½å¼æ”¹ç‚º CrossEntropyLoss (ç”¨æ–¼å¤šé¡åˆ¥åˆ†å‰²)
    # é®ç½© (masks) å¿…é ˆæ˜¯ LongTensor ä¸” shape ç‚º (N, H, W)
    loss_fn = nn.CrossEntropyLoss() 
    optimizer = optim.Adam(model.parameters(), lr=1e-4)

    epochs = 30
    current_best_loss = float('inf')

    print("\né–‹å§‹è¨“ç·´...\n")

    for epoch in range(1, epochs + 1):
        model.train()
        epoch_loss = 0

        print(f"\n==== Epoch {epoch}/{epochs} ====\n")

        for batch_idx, (imgs, masks) in enumerate(loader):
            imgs = imgs.to(device)
            # é®ç½© (masks) å·²ç¶“æ˜¯ LongTensor ä¸”ç¶­åº¦æ­£ç¢º (N, H, W)
            masks = masks.to(device) 

            preds = model(imgs) # preds shape: (N, C, H, W)
            loss = loss_fn(preds, masks)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()

            print(f"[{batch_idx+1}/{len(loader)}] loss={loss.item():.4f}")

            # --- å¯è¦–åŒ–ç¬¬ä¸€å¼µ sample ---
            if batch_idx == 0:
                # é æ¸¬çµæœå– argmax (å¾ C ç¶­åº¦ä¸­é¸æ“‡æ©Ÿç‡æœ€é«˜çš„é¡åˆ¥)
                pred_mask = torch.argmax(preds[0], dim=0).cpu() # (H, W)
                # è¼¸å‡ºåˆ° visualize/ ç›®éŒ„ (masks[0] æ˜¯ (H, W))
                visualize_epoch(imgs[0].cpu(), masks[0].cpu(), pred_mask,
                                f"epoch{epoch}")

        # å„²å­˜ Checkpoint
        avg_loss = epoch_loss / len(loader)
        print(f"Epoch {epoch} è¨“ç·´å®Œæˆ. Avg Loss: {avg_loss:.4f}")
        
        # å„²å­˜ç•¶å‰ Checkpoint
        current_ckpt_path = os.path.join(checkpoint_dir, f"unet_epoch{epoch}.pth")
        torch.save(model.state_dict(), current_ckpt_path)

        # ğŸš¨ ä¿®æ­£: ç‚ºäº†è®“ Streamlit æ‡‰ç”¨ç¨‹å¼å§‹çµ‚è¼‰å…¥æœ€æ–°çš„æ¨¡å‹ï¼Œæˆ‘å€‘åªä¿ç•™ä¸€å€‹æª”æ¡ˆã€‚
        # åˆªé™¤å‰ä¸€å€‹ Checkpoint
        if epoch > 1:
             prev_ckpt_path = os.path.join(checkpoint_dir, f"unet_epoch{epoch-1}.pth")
             if os.path.exists(prev_ckpt_path):
                os.remove(prev_ckpt_path)
                print(f"å·²åˆªé™¤èˆŠ Checkpoint: {os.path.basename(prev_ckpt_path)}")
        
        # è®“ Streamlit æ‡‰ç”¨ç¨‹å¼è¼‰å…¥é€™å€‹æª”æ¡ˆ
        # é€™è£¡å¯ä»¥é¸æ“‡å°‡æœ€å¥½çš„æ¨¡å‹å¦å¤–å„²å­˜ (Best Model)
        if avg_loss < current_best_loss:
            current_best_loss = avg_loss
            best_ckpt_path = os.path.join(checkpoint_dir, "best_unet_model.pth")
            torch.save(model.state_dict(), best_ckpt_path)
            print(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹å·²å„²å­˜: {os.path.basename(best_ckpt_path)}")


if __name__ == "__main__":
    main()