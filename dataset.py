import os
import torch
from torch.utils.data import Dataset
from PIL import Image
import numpy as np

class InvoiceSegDataset(Dataset):
    def __init__(self, images_dir, masks_dir, transform=None, mask_transform=None):
        self.images_dir = images_dir
        self.masks_dir = masks_dir
        self.transform = transform
        self.mask_transform = mask_transform

        # 1. è®€å–æ‰€æœ‰åœ–ç‰‡æª”å
        all_image_names = [f for f in os.listdir(images_dir)
                           if f.lower().endswith((".jpg", ".jpeg", ".png"))]

        # 2. å»ºç«‹ä¸€å€‹é®ç½©æª”æ¡ˆçš„æŸ¥æ‰¾è¡¨ (Map)
        # éµ: åŸºç¤åç¨± (e.g., '1', '126', '001')
        # å€¼: å®Œæ•´è·¯å¾‘ (e.g., 'masks/001.png')
        mask_map = {}
        for mask_name in os.listdir(masks_dir):
            if mask_name.lower().endswith((".jpg", ".jpeg", ".png")):
                base_name = mask_name.rsplit(".", 1)[0]
                mask_map[base_name] = os.path.join(masks_dir, mask_name)

        # 3. æ‰¾å‡ºæœ‰æ•ˆçš„åœ–ç‰‡-é®ç½©é…å°
        self.images_to_load = []
        for img_name in all_image_names:
            base_name = img_name.rsplit(".", 1)[0]
            
            # --- å˜—è©¦å¹¾ç¨®å¸¸è¦‹çš„å‘½åé…å°é‚è¼¯ ---
            
            # å˜—è©¦ 1: åœ–ç‰‡åŸºç¤å (e.g., '126')
            if base_name in mask_map:
                self.images_to_load.append({
                    'img_name': img_name,
                    'mask_path': mask_map[base_name]
                })
                continue
                
            # å˜—è©¦ 2: å¦‚æœåœ–ç‰‡åç¨±æ˜¯æ•¸å­—ï¼Œå˜—è©¦è£œé›¶é…å° (e.g., '1' -> '001', '01')
            if base_name.isdigit():
                num = int(base_name)
                # å˜—è©¦ 001, 01, 0001
                for padding in [2, 3, 4]: 
                    padded_name = f"{num:0{padding}d}"
                    if padded_name in mask_map:
                        self.images_to_load.append({
                            'img_name': img_name,
                            'mask_path': mask_map[padded_name]
                        })
                        break # æ‰¾åˆ°å¾Œè·³å‡º padding è¿´åœˆ
                else:
                    # å¦‚æœå…§å±¤ for è¿´åœˆæ²’æœ‰ break (è¡¨ç¤ºæ²’æ‰¾åˆ°é…å°)ï¼Œå‰‡ç¹¼çºŒä¸‹ä¸€å€‹åœ–ç‰‡
                    continue
            
            # å˜—è©¦ 3: å¦‚æœé®ç½©åç¨±æ˜¯æ•¸å­—ï¼Œå˜—è©¦åœ–ç‰‡åç¨±ä¸è£œé›¶é…å°
            # (å·²ç¶“åœ¨å˜—è©¦ 1, 2 ä¸­æ¶µè“‹äº†)
            
        print(f"ğŸ“Œ è³‡æ–™é›†è¼‰å…¥ï¼š{len(self.images_to_load)} å¼µåœ–ç‰‡")
        if len(self.images_to_load) == 0:
             print("âš ï¸ è­¦å‘Šï¼šæ²’æœ‰æ‰¾åˆ°ä»»ä½•é…å°çš„åœ–ç‰‡å’Œé®ç½©æª”æ¡ˆã€‚è«‹æª¢æŸ¥ 'data/images' å’Œ 'masks' è³‡æ–™å¤¾çš„æª”æ¡ˆåç¨±æ˜¯å¦ä¸€è‡´æˆ–æœ‰è£œé›¶å·®ç•°ã€‚")


    def __len__(self):
        return len(self.images_to_load)

    def __getitem__(self, idx):
        item = self.images_to_load[idx]
        img_name = item['img_name']
        mask_path = item['mask_path']

        # load image
        img_path = os.path.join(self.images_dir, img_name)
        img = Image.open(img_path).convert("RGB")

        # è¼‰å…¥é®ç½©ä¸¦è½‰ç‚ºç°åº¦åœ– (L)
        # mask_path ç¾åœ¨å·²ç¶“æ˜¯æ­£ç¢ºçš„å®Œæ•´è·¯å¾‘
        mask = Image.open(mask_path).convert("L")
        mask_np = np.array(mask)
        
        # é®ç½©é‡åŒ–ï¼šå°‡ 0-255 çš„ç°åº¦å€¼é‡åŒ–ç‚º 0, 1, 2, 3 å››å€‹é¡åˆ¥ ID
        # å‡è¨­æœ€å¤§å€¼æ˜¯ 255ï¼Œæˆ‘å€‘é™¤ä»¥ (255/3) ä¾†é‡åŒ–ï¼Œå››æ¨äº”å…¥åˆ°æœ€è¿‘çš„æ•´æ•¸
        mask_np = np.round(mask_np / (255 / 3.0)).astype(np.int64)

        # ç¢ºä¿å€¼åœ¨ [0, N_CLASSES-1] ç¯„åœå…§
        mask_np = np.clip(mask_np, 0, 3) # 4 å€‹é¡åˆ¥: 0, 1, 2, 3 (UNet çš„è¼¸å‡ºé¡åˆ¥æ•¸æ‡‰ç‚º 4)

        if self.transform:
            img = self.transform(img)

        # é®ç½©è½‰ç‚º LongTensor
        if self.mask_transform:
            # å¿…é ˆä½¿ç”¨ PIL Image æ‰èƒ½æ‡‰ç”¨ Resize æˆ–å…¶ä»–è®Šæ›
            mask_img = self.mask_transform(Image.fromarray(mask_np, mode='L'))
            # è½‰æ›ç‚º LongTensor (CrossEntropyLoss è¦æ±‚çš„æ ¼å¼)
            mask_tensor = torch.as_tensor(np.array(mask_img), dtype=torch.long)
        else:
            mask_tensor = torch.as_tensor(mask_np, dtype=torch.long)
            
        return img, mask_tensor